{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVaG71Po2qOD"
   },
   "source": [
    "# Redes Neuronales\n",
    "## Trabajo Práctico N° 1 - Ejercicio 1\n",
    "* Kammann, Lucas Agustín\n",
    "* Gaytan, Joaquín Oscar\n",
    "\n",
    "### Consultas y/o dudas\n",
    "* Métricas del modelo (Matriz de confusión, exactitud, precisión, etc.)\n",
    "* Procesamiento de los datos? (Filtrado)\n",
    "* CountVectorizer, es necesario que lo hagamos a mano o podemos utilizar la librería de sci-kit-learn?\n",
    "* Filtrado de numeros\n",
    "* Filtrado de palabras\n",
    "\n",
    "### Step by step\n",
    "* Obtención del dataset (separando entre \"train\" y \"test\")\n",
    "* Preprocesamiento de los datos\n",
    "* Distribuciones condicionales (Verosimilitudes/Likelihood)\n",
    "* Smoothing\n",
    "* Probabilidad a Priori\n",
    "* Clasificación (Naive Bayes Multinomial)\n",
    "* Clasificación usando log posteriori\n",
    "* Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del problema\n",
    "Se desea armar un clasificador de correos electrónicos o noticias en función del tópico sobre el cual trata dicho correo electrónico o noticia, para ello, se modela el problema considerando una variable aleatoria discreta $X$ con distribución categórica de $k_x = 20$ categorías, siendo estas los tópicos posibles que pueden tratar los documentos clasificados.\n",
    "\n",
    "$$X \\sim Categorica(p_1, p_2, ..., p_{k_x})$$\n",
    "\n",
    "Las características a analizar de los documentos para la clasificación, son las palabras. Se asume que el orden de las palabras no importa, que son independientes entre sí y que se encuentran identicamente distribuídas. De esta forma, se define una segunda variable aleatoria discreta $Y$ con distribución categórica de $k_y$ categorías, siendo estas las posibles palabras de nuestro vocabulario.\n",
    "\n",
    "$$Y \\sim Categorica(p_1, p_2, ..., p_{k_y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de la base de datos\n",
    "Usamos la librería **sklearn** para descargar la base de datos de entrenamiento y de validación, ya que se encontraba disponible en sus datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18842,
     "status": "ok",
     "timestamp": 1616464689182,
     "user": {
      "displayName": "JOAQUÍN OSCAR GAYTAN",
      "photoUrl": "",
      "userId": "15176508666834216481"
     },
     "user_tz": 180
    },
    "id": "NCv8VNLQ2k7R",
    "outputId": "270d983e-17a6-4a3a-c82f-f6e6a0ce6faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Train: 11314 elements\n",
      "Dataset Test: 7532 elements\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "# Loading the datasets\n",
    "train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# Categories\n",
    "categories = train.target_names\n",
    "\n",
    "# Train dataset, casting to numpy array\n",
    "train_raw_input = np.array(train.data)\n",
    "train_output = np.array(train.target)\n",
    "train_size = len(train_raw_input)\n",
    "\n",
    "# Test dataset, casting to numpy array\n",
    "test_raw_input = np.array(test.data)\n",
    "test_output = np.array(test.target)\n",
    "test_size = len(test_raw_input)\n",
    "\n",
    "# Logging useful information\n",
    "print(f'Dataset Train: {train_size} elements')\n",
    "print(f'Dataset Test: {test_size} elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando la base de datos\n",
    "\n",
    "## Observando un correo electrónico de forma aleatoria\n",
    "Buscamos de forma aleatoria un elemento dentro de la base de datos de entrenamiento, con el objetivo de visualizar cómo suelen ser los correos electrónicos de noticias que se poseen, para tener una mejor comprensión de qué podemos llegar a encontrarnos dentro del vocabulario o el documento a analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: dbak@elm.lle.rochester.edu (Douglas Baker)\n",
      "Subject: Performance of new Mustangs !!!!!!!!!!!!!!!!!!!!!\n",
      "Article-I.D.: galileo.1993Apr6.170901.7684\n",
      "Organization: University of Rochester, Rochester NY\n",
      "Lines: 9\n",
      "Nntp-Posting-Host: elm.lle.rochester.edu\n",
      "\n",
      "\n",
      "\tDoes anyone know the performance ratings for a 1992 or 1993\n",
      "5.0 L HO Mustang LX like the 0-60 time 1/4 mile and top end ???\n",
      "Also can you tell me which magazine where these #'s come from so I\n",
      "can look them up if possable ????  If you could the year and month and\n",
      "eveen page # if you have it.\n",
      "\n",
      "\t\t\t\t\t\tThanks,\n",
      "\t\t\t\t\t\tDoug\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_data = np.random.choice(train_raw_input)\n",
    "print(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorías\n",
    "Dentro de la base de datos, los correos electrónicos que podemos encontrar pueden tratar de diferentes tópicos, y estos tópicos son las categorías de la variable aleatoria definida $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1616464712787,
     "user": {
      "displayName": "JOAQUÍN OSCAR GAYTAN",
      "photoUrl": "",
      "userId": "15176508666834216481"
     },
     "user_tz": 180
    },
    "id": "9Xh-PLNI7WsW",
    "outputId": "1665e32b-4e8b-491f-f4a2-d4115f937cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Show the news categories\n",
    "pprint.pprint(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograma de tópicos\n",
    "Se calcula y grafica el histograma de los tópicos de las noticias o correos electrónicos utilizando la librería **matplotlib**. Del resultado obtenido, se pueden hacer algunos comentarios,\n",
    "* A simple vista, la distribución es relativamente cercana a una distribución uniforme\n",
    "* El clasificador trivial tendría una exactitud de aproximadamente 0,05\n",
    "\n",
    "# TODO! Más lindo el grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 4780,
     "status": "ok",
     "timestamp": 1616376899482,
     "user": {
      "displayName": "LUCAS KAMMANN",
      "photoUrl": "",
      "userId": "12661655261825067035"
     },
     "user_tz": 180
    },
    "id": "R7Jl_PbkC7CY",
    "outputId": "9fbc462e-28ed-4cc0-b7a7-9254af2e7597"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Histogram for the categories in the training set\n",
    "priori, _, _ = plt.hist(train_output, bins=len(categories), range=(0,len(categories)), rwidth=0.5, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the priori probability distribution: (20,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the priori probability distribution: {priori.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de probabilidades a priori\n",
    "Se computan las probabilidades a priori para las categorías, es decir, los tópicos. Se emplea una herramienta distinta a **matplotlib** para comparar el tiempo utilizada en el procesamiento. Se está estimando la siguiente función masa de probabilidad,\n",
    "$$P(X=x) ; x = 0, 1, ..., 19$$\n",
    "\n",
    "Para ello, se emplea como estimador la proporción de cada categoría dentro del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For each category, filter the amount of occurences in the training dataset\n",
    "# the compute the priori probability\n",
    "priori_distribution = np.zeros(len(categories))\n",
    "for index, category in enumerate(categories):\n",
    "    frequency = (train_output == index).sum()\n",
    "    priori_distribution[index] = frequency\n",
    "priori_distribution /= priori_distribution.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "Para trabajar con multinomial naive bayes es necesario poder modelar las características de entrada de forma numérica, para ello se definió una variable aleatoria categórica que corresponde a las palabras. Así, asumiendo que el orden de las palabras dentro de un texto no importa, y considerando que las palabras son independientes e igualmente distribuídas, para encontrar dicha distribución es necesario realizar un mapeo de las palabras con los valores numéricos de una variable y luego estimar dicha distribución.\n",
    "\n",
    "## Tokenización\n",
    "El proceso de tokenización implica tomar el texto e identificar todas las palabras distintas que se encuentran en el mismo y luego contar la cantidad de ocurrencias que tienen, es decir, cuál es la frecuencia absoluta de las palabras dentro de un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "VTY7lCEeMQWC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Importing and testing the CountVectorizer class of sklearn\n",
    "vectorizer = TfidfVectorizer(min_df=5, strip_accents='ascii', stop_words='english', encoding='latin1')\n",
    "train_input = vectorizer.fit_transform(train_raw_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>0000000004</th>\n",
       "      <th>0001</th>\n",
       "      <th>000152</th>\n",
       "      <th>0002</th>\n",
       "      <th>0005</th>\n",
       "      <th>0005111312</th>\n",
       "      <th>00072</th>\n",
       "      <th>...</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumabot</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyeh</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 25636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  0000  0000000004  0001  000152  0002  0005  0005111312  \\\n",
       "0      0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "1      0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "2      0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "3      0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "4      0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "...    ...  ...   ...         ...   ...     ...   ...   ...         ...   \n",
       "11309  0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "11310  0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "11311  0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "11312  0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "11313  0.0  0.0   0.0         0.0   0.0     0.0   0.0   0.0         0.0   \n",
       "\n",
       "       00072  ...  zuma  zumabot  zur  zurich   zv   zw   zx   zy  zyeh   zz  \n",
       "0        0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "1        0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "2        0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "3        0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "4        0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "...      ...  ...   ...      ...  ...     ...  ...  ...  ...  ...   ...  ...  \n",
       "11309    0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "11310    0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "11311    0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "11312    0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "11313    0.0  ...   0.0      0.0  0.0     0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "\n",
       "[11314 rows x 25636 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_input.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 25636)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de distribución de probabilidad condicional\n",
    "\n",
    "# TODO! Estimación\n",
    "\n",
    "## Overfitting\n",
    "El **overfitting** es un problema que ocurre cuando el modelo utilizado no es capaz de predecir correctamente frente a datos nuevos que no se encontraban en el conjunto de entrenamiento, lo cual le quita capacidad de generalizar, un aspecto fundamental en la resolución de problemas de inteligencia artificial. En este caso, para resolver el problema descripto se propone emplear un clasificador naive bayes multinomial, que puede traer apareado un problema de overfitting que se ilustra a continuación.\n",
    "\n",
    "Sea un texto compuesto por $N$ palabras, para clasificarlo se busca la máxima probabilidad a posteriori, es decir aquella categoría $y$ para la cual la probabilidad de que ese texto pertenezca sea máxima a comparación de otras categorías,\n",
    "\n",
    "$$P(y|x_1,...,x_N)=\\frac{P(x_1,...,x_N|y) \\cdot P(y)}{P(x_1,...,x_N)}$$\n",
    "\n",
    "Aplicando naive bayes, se asumen que las palabras son independientes y luego se añade que sean idénticamente distruidas según el tipo de problema que nos proponemos resolver, entonces\n",
    "\n",
    "$$P(y|x_1,...,x_N)=\\frac{P(x_1|y) \\cdot ... \\cdot P(x_N|y) \\cdot P(y)}{P(x_1,...,x_N)}$$\n",
    "\n",
    "En función de cómo se estima la distribución de probabilidades, una palabra $x_1$ que no apareció en una categoría durante el entrenamiento fue ponderada con una probabilidad nula, lo cual hace que todo el producto se anule, y si la probabilidad fuera muy grande, por culpa de esta única palabra toda la probabilidad a posteriori se anula llevando a una predicción errónea. Para solucionar esto, se propone emplear el método de Laplacian Smoothing.\n",
    "\n",
    "## Laplacian Smoothing\n",
    "El método de Laplacian Smoothing consiste en agregar un cierto conocimiento a priori dentro de la distribución estimada, de forma tal que cuando no se posee demasiada evidencia durante el entrenamiento, la información aportada por tal conocimiento a priori nos permite evitar caer en el escenario de las probabilidades nulas.\n",
    "\n",
    "El procedimiento consiste en fijar el valor de un **hiperparámetro** $\\alpha$, que se suma como cantidad de ocurrencias a cada palabra durante el análisis de frecuencias absolutas en la etapa de estimación. Así, se introduce un conocimiento a priori de cantidad de ocurrencias igual para todas las palabras, es decir, estamos diciendo que sin información supondríamos que la distribución es uniforme. Por lo general, la magnitud de este parámetro define qué tanta información de entrenamiento se necesita para que deje de valer dicho conocimiento a priori.\n",
    "\n",
    "### Discusiones sobre Laplacian Smoothing\n",
    "* https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "* https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf\n",
    "* https://stats.stackexchange.com/questions/108797/in-naive-bayes-why-bother-with-laplace-smoothing-when-we-have-unknown-words-in\n",
    "* https://courses.cs.washington.edu/courses/cse446/20wi/Section7/naive-bayes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "zbu8XISsgck7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Separate the matrix of documents (mails) and occurrences of words for each category\n",
    "# and compute the normalized distribution to get the likelihood for each category\n",
    "alpha = 0.01\n",
    "categories_distribution = np.zeros((len(categories), len(vectorizer.vocabulary_.keys())), dtype=np.longdouble)\n",
    "for index, category in enumerate(categories):\n",
    "  category_matrix = train_input[train_output == index][:]\n",
    "  distribution = category_matrix.sum(axis=0) + alpha\n",
    "  categories_distribution[index,:] = distribution / distribution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 25636)\n"
     ]
    }
   ],
   "source": [
    "print(categories_distribution.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación por máximo a posteriori\n",
    "El criterio del clasificador de naive bayes consiste en el máximo a posteriori, es decir, buscamos la categoria que maximiza la probabilidad de que sea esa categoría dada la información de las características que recibimos.\n",
    "\n",
    "Es importante notar que, en la expresión del máximo a posteriori, la probabilidad total de que ocurran conjuntamente las características, es un término invariante para cada categoría. Esto implica, que a los fines de comparar cuál es mayor, sin importar cuánto sea numéricamente esa probabilidad a posteriori, ese término es redundante. Es por esto que fue removido para reducir la carga computacional del algoritmo.\n",
    "\n",
    "# TODO! Explicar la cuenta desde la potencia de las palabras\n",
    "\n",
    "### Problema numérico\n",
    "Si el preprocesamiento no se vuelve lo suficientemente estricto y no limita el vocabulario, la cantidad de palabras provoca que los valores numéricos obtenidos en la verosimilitud sean demasiado chicos y empiezan a darse errores numéricos por la precisión del punto flotante empleado por NumPy.\n",
    "\n",
    "Este problema se encontró comparando este modelo con el de log probabilidades, y se pudo observar que si se escala la distribución (no se la normaliza), entonces el problema numérico desaparece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Taking a subset of the testing set, to avoid using the complete set\n",
    "# when the algorithm is too slow... remember this is not strictly the test\n",
    "# or validation of the model, we are doing only an analysis and it is not required\n",
    "# for us in this instance to use the complete set\n",
    "sub_test_input_size = input_size\n",
    "sub_text_raw_input = test_raw_input[:input_size]\n",
    "sub_test_output = test_output[:input_size]\n",
    "sub_test_input = vectorizer.transform(sub_text_raw_input)\n",
    "\n",
    "# Computing predictions for each input\n",
    "predictions = np.zeros(sub_test_input.shape[0], dtype=int)\n",
    "for input_index in range(sub_test_input.shape[0]):\n",
    "    # Computing the posteriori probability\n",
    "    posteriori_unnormalized = ((categories_distribution) ** sub_test_input.toarray()[input_index]).prod(axis=1) * priori\n",
    "\n",
    "    # Choosing the maximum posteriori probability as the prediction\n",
    "    predictions[input_index] = posteriori_unnormalized.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Computing the accuracy of the model\n",
    "accuracy = (predictions == sub_test_output).sum() / input_size\n",
    "print(f'Accuracy obtained: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación utilizando log probabilidades\n",
    "\n",
    "Si consideramos que el denominador de la expresión del máximo a posteriori es un término invariante a las categorías, por lo cual lo removemos, y luego aplicamos el logaritmo natural, obtenemos una expresión de la siguiente forma,\n",
    "\n",
    "$$ln[P(y|x_1,...,x_N)] \\propto ln[P(x_1|y)] + ... + ln[P(x_N|y)] + ln[P(y)]$$\n",
    "\n",
    "Computacionalmente, esto se vuelve más sencillo de manejar porque ...\n",
    "\n",
    "# TODO! Explicar el producto punto entre vectores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Log probabilities\n",
    "log_priori = np.log(priori)\n",
    "log_prob = np.log(categories_distribution)\n",
    "\n",
    "# Data, target and vectorizer\n",
    "sub_test_input_size = test_size\n",
    "sub_text_raw_input = test_raw_input[:sub_test_input_size]\n",
    "sub_test_output = test_output[:sub_test_input_size]\n",
    "sub_test_input = vectorizer.transform(sub_text_raw_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Computing the log posteriori probability\n",
    "log_posteriori = np.dot(log_prob, sub_test_input.todense().transpose()) + (log_priori.reshape(-1, 1) * np.ones(sub_test_input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Choosing the maximum log posteriori probability as the prediction\n",
    "predictions = np.zeros(sub_test_input.shape[0], dtype=int)\n",
    "for input_index in range(input_size):\n",
    "    predictions[input_index] = log_posteriori[:,input_index].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas\n",
    "\n",
    "* https://www.iartificial.net/precision-recall-f1-accuracy-en-clasificacion/\n",
    "* https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/\n",
    "\n",
    "# TODO! Explicar cada métrica y cada fórmula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained: 0.0523101433882103\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Accuracy (Exactitud)\n",
    "accuracy = metrics.accuracy_score(sub_test_output, predictions)\n",
    "print(f'Accuracy obtained: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Matriz de Confusión')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = metrics.confusion_matrix(sub_test_output, predictions)\n",
    "plt.matshow(cmatrix)\n",
    "plt.colorbar()\n",
    "plt.title(\"Matriz de Confusión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04263045 0.75       0.33333333 0.75       0.75       1.\n",
      " 1.         0.83333333 1.         1.         0.8        0.75\n",
      " 0.5        1.         1.         0.75       1.         0.875\n",
      " 0.8        0.25      ]\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "precision = metrics.precision_score(sub_test_output, predictions, average=None)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99373041 0.01542416 0.00507614 0.01530612 0.00779221 0.01012658\n",
      " 0.00769231 0.01262626 0.01758794 0.01259446 0.01002506 0.00757576\n",
      " 0.00254453 0.00505051 0.01269036 0.00753769 0.01648352 0.01861702\n",
      " 0.01290323 0.00398406]\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "recall = metrics.recall_score(sub_test_output, predictions, average=None)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08175371 0.0302267  0.01       0.03       0.01542416 0.02005013\n",
      " 0.01526718 0.02487562 0.0345679  0.02487562 0.01980198 0.015\n",
      " 0.00506329 0.01005025 0.02506266 0.01492537 0.03243243 0.03645833\n",
      " 0.02539683 0.00784314]\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "f1 = metrics.f1_score(sub_test_output, predictions, average=None)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.99      0.08       319\n",
      "           1       0.75      0.02      0.03       389\n",
      "           2       0.33      0.01      0.01       394\n",
      "           3       0.75      0.02      0.03       392\n",
      "           4       0.75      0.01      0.02       385\n",
      "           5       1.00      0.01      0.02       395\n",
      "           6       1.00      0.01      0.02       390\n",
      "           7       0.83      0.01      0.02       396\n",
      "           8       1.00      0.02      0.03       398\n",
      "           9       1.00      0.01      0.02       397\n",
      "          10       0.80      0.01      0.02       399\n",
      "          11       0.75      0.01      0.02       396\n",
      "          12       0.50      0.00      0.01       393\n",
      "          13       1.00      0.01      0.01       396\n",
      "          14       1.00      0.01      0.03       394\n",
      "          15       0.75      0.01      0.01       398\n",
      "          16       1.00      0.02      0.03       364\n",
      "          17       0.88      0.02      0.04       376\n",
      "          18       0.80      0.01      0.03       310\n",
      "          19       0.25      0.00      0.01       251\n",
      "\n",
      "    accuracy                           0.05      7532\n",
      "   macro avg       0.76      0.06      0.02      7532\n",
      "weighted avg       0.77      0.05      0.02      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(sub_test_output, predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP1-EJ1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
