{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales - Trabajo Práctico N° 1 - Ejercicio 2 - Notebook #2\n",
    "En esta segunda notebook, se busca definir cuál métrica es más apropiada para analizar la performance del modelo y qué hiper parámetros se van a utilizar para el ajuste del modelo acorde a la validación. Finalmente, estas decisiones se vuelcan en la selección del mejor modelo para el problema de la clasificación de correos electrónicos asociados grupos de noticias.\n",
    "\n",
    "### Fuentes útiles\n",
    "* https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "* https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
    "* https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "* https://stackoverflow.com/questions/58046129/can-someone-give-a-good-math-stats-explanation-as-to-what-the-parameter-var-smoo\n",
    "\n",
    "### Integrantes del grupo\n",
    "* Gaytan, Joaquín Oscar\n",
    "* Kammann, Lucas Agustín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Métrica\n",
    "La métrica a utilizar para cuantificar la performance de los modelos, seleccionar los hiperparámetros y validarlos, será la **sensibilidad** o **recall**.\n",
    "\n",
    "## 1.1. Justificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparación de los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Cargando el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database from .csv\n",
    "df = pd.read_csv('../assets/diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de valores inválidos\n",
    "Se filtran los valores que se consideran inválidos para las variables en cuestión, estas consideraciones se obtuvieron como resultado del análisis realizado en el notebook #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Glucose values\n",
    "df['Glucose'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Blood Pressure values\n",
    "df['BloodPressure'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Skin Thickness values\n",
    "df['SkinThickness'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Insulin values\n",
    "df['Insulin'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Body Mass Index values\n",
    "df['BMI'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Filtrado de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper import remove_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    remove_outliers(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>764.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>749.000000</td>\n",
       "      <td>739.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.786649</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.115438</td>\n",
       "      <td>28.903346</td>\n",
       "      <td>132.610811</td>\n",
       "      <td>32.204005</td>\n",
       "      <td>0.429832</td>\n",
       "      <td>32.805007</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.278714</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>11.239072</td>\n",
       "      <td>9.865480</td>\n",
       "      <td>74.285393</td>\n",
       "      <td>6.491385</td>\n",
       "      <td>0.249684</td>\n",
       "      <td>11.113182</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   764.000000  763.000000     719.000000     538.000000  370.000000   \n",
       "mean      3.786649  121.686763      72.115438      28.903346  132.610811   \n",
       "std       3.278714   30.535641      11.239072       9.865480   74.285393   \n",
       "min       0.000000   44.000000      40.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      64.000000      22.000000   75.000000   \n",
       "50%       3.000000  117.000000      72.000000      29.000000  120.000000   \n",
       "75%       6.000000  141.000000      80.000000      36.000000  177.500000   \n",
       "max      13.000000  199.000000     104.000000      56.000000  360.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  749.000000                739.000000  759.000000  768.000000  \n",
       "mean    32.204005                  0.429832   32.805007    0.348958  \n",
       "std      6.491385                  0.249684   11.113182    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.400000                  0.238000   24.000000    0.000000  \n",
       "50%     32.000000                  0.356000   29.000000    0.000000  \n",
       "75%     36.500000                  0.587000   40.000000    1.000000  \n",
       "max     50.000000                  1.191000   66.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Separación de datasets\n",
    "Se separa el dataset original en los datasets de train, valid y test. Además, se debe corregir que los valores inválidos del dataset original fueron reemplazados por el valor NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into the total train and the test datasets, because\n",
    "# the total train contains the train and valid datasets used for\n",
    "# hiper parameter selection\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean of training\n",
    "train_means = train.mean().to_numpy()\n",
    "\n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(train.columns):\n",
    "    train.loc[:,column].replace(np.nan, train_means[index], inplace=True)\n",
    "\n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(test.columns):\n",
    "    test.loc[:,column].replace(np.nan, train_means[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the inputs and outputs of the train dataset\n",
    "x_train = train.to_numpy()[:,:8]\n",
    "y_train = train.to_numpy()[:,8]\n",
    "\n",
    "# Extracting the inputs and outputs of the test dataset\n",
    "x_test = test.to_numpy()[:,:8]\n",
    "y_test = test.to_numpy()[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Selección de modelo e hiper parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from src.gaussian_naive_bayes import BinaryGaussianNaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Entrenamiento de todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 80.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=BinaryGaussianNaiveBayes(bessel_correction=False,\n",
       "                                                smoothing=0),\n",
       "             param_grid={'bessel_correction': [False],\n",
       "                         'filter_variables': [[True, True, True, True, False,\n",
       "                                               True, False, False]],\n",
       "                         'smoothing': [0]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Hiper parameters\n",
    "parameters = {\n",
    "    'smoothing': [0],\n",
    "    'bessel_correction': [False],\n",
    "    'filter_variables': [[True, True, True, True, False, True, False, False]]\n",
    "}\n",
    "\n",
    "# Estimator or model\n",
    "estimator = BinaryGaussianNaiveBayes()\n",
    "\n",
    "# GridSearch Cross-Validation\n",
    "grid = GridSearchCV(estimator, parameters, cv=5, scoring='recall')\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bessel_correction': False, 'filter_variables': [True, True, True, True, False, True, False, False], 'smoothing': 0}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6120278971903284\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Entrenamiento completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "classifier = BinaryGaussianNaiveBayes(\n",
    "    smoothing=grid.best_params_['smoothing'], \n",
    "    bessel_correction=grid.best_params_['bessel_correction'], \n",
    "    filter_variables=grid.best_params_['filter_variables']\n",
    ")\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validación y performance del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084745762711864\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Comparación con KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "class BinaryKDENaiveBayes(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, kernel='gaussian', bandwidth=0.5, filter_variables=None):\n",
    "        self.priori_distribution = None\n",
    "        self.log_priori_distribution = None\n",
    "        self.filter_variables = filter_variables\n",
    "        self.kde = None\n",
    "        self.kernel = kernel\n",
    "        self.bandwidth = bandwidth\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        # Instantiating KDE objects\n",
    "        self.kde = [KernelDensity(kernel=self.kernel, bandwidth=self.bandwidth), KernelDensity(kernel=self.kernel, bandwidth=self.bandwidth)]\n",
    "        # Filtering data if required\n",
    "        if self.filter_variables is not None:\n",
    "            x_data = x_data[:,self.filter_variables]\n",
    "        \n",
    "        # Calculating priori distribution\n",
    "        self.priori_distribution = np.array([len(y_data[y_data == 0]) , len(y_data[y_data == 1])])\n",
    "        self.priori_distribution = self.priori_distribution / self.priori_distribution.sum()\n",
    "        self.log_priori_distribution = np.log(self.priori_distribution)\n",
    "        \n",
    "        # Fitting data into KDE object\n",
    "        self.kde[0].fit(x_data[y_data == 0])\n",
    "        self.kde[1].fit(x_data[y_data == 1])\n",
    "            \n",
    "    def predict(self, x_data):\n",
    "        # Filtering data if required\n",
    "        if self.filter_variables is not None:\n",
    "            x_data = x_data[:,self.filter_variables]\n",
    "            \n",
    "        # Initialization of predictions\n",
    "        predictions = np.zeros(x_data.shape[0])\n",
    "        \n",
    "        # Prediction for each subject\n",
    "        for subject_index in range(x_data.shape[0]):\n",
    "            \n",
    "            log_likelihood = np.array([self.kde[0].score(x_data[subject_index].reshape(1, -1)), self.kde[1].score(x_data[subject_index].reshape(1, -1))])\n",
    "            log_posteriori_unnormalized = log_likelihood + self.log_priori_distribution\n",
    "            log_odds = log_posteriori_unnormalized[1] - log_posteriori_unnormalized[0]\n",
    "            predictions[subject_index] = 1 if log_odds > 0 else 0\n",
    "        \n",
    "        # Return the predictions made by the model\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=BinaryKDENaiveBayes(),\n",
       "             param_grid={'bandwidth': array([0.0001  , 0.025075, 0.05005 , 0.075025, 0.1     ]),\n",
       "                         'filter_variables': [[False, False, False, False,\n",
       "                                               False, False, False, True],\n",
       "                                              [False, False, False, False,\n",
       "                                               False, False, True, False],\n",
       "                                              [False, False, False, False,\n",
       "                                               False, False, True, True],\n",
       "                                              [False, False, False, False,\n",
       "                                               False, True, False, False],\n",
       "                                              [False, False, Fa...\n",
       "                                               False, False, False],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               False, False, True],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               False, True, False],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               False, True, True],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               True, False, False],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               True, False, True],\n",
       "                                              [False, False, False, True, True,\n",
       "                                               True, True, False], ...],\n",
       "                         'kernel': ['exponential', 'gaussian']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Wait time: 11min\n",
    "# Hiper parameters\n",
    "param = {\n",
    "    'kernel': ['exponential', 'gaussian'],\n",
    "    'bandwidth': np.linspace(0.0001,0.1, 5),\n",
    "    'filter_variables': [[(i & (0x1 << (7-j)) > 0) for j in range(8)] for i in range(1,256)] # If all columns disabled, then kde fails\n",
    "}\n",
    "\n",
    "# Estimator or model\n",
    "estimator = BinaryKDENaiveBayes()\n",
    "\n",
    "\n",
    "# GridSearch Cross-Validation\n",
    "grid = GridSearchCV(estimator, param, cv=5, scoring='recall')\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bandwidth': 0.0001, 'filter_variables': [False, True, True, True, True, False, False, True], 'kernel': 'exponential'}\n"
     ]
    }
   ],
   "source": [
    "# Get best model params\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6843732849291427\n"
     ]
    }
   ],
   "source": [
    "# Get model best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5932203389830508\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Estimator or model\n",
    "#filter_variables=[True, True, True, True, False, True, False, False]\n",
    "estimator = BinaryKDENaiveBayes(kernel='exponential', bandwidth=1.0)\n",
    "estimator.fit(x_train, y_train)\n",
    "p = estimator.predict(x_test)\n",
    "\n",
    "score = recall_score(y_test, p)\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Contrastando con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084745762711864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create and train the model\n",
    "c = GaussianNB()\n",
    "c.fit(x_train[:,grid.best_params_['filter_variables']], y_train)\n",
    "\n",
    "# Predict and compute score\n",
    "p = c.predict(x_test[:,grid.best_params_['filter_variables']])\n",
    "score = recall_score(y_test, p)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
