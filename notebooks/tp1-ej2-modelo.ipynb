{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales - Trabajo Práctico N° 1 - Ejercicio 2 - Notebook #2\n",
    "En esta segunda notebook, se busca definir cuál métrica es más apropiada para analizar la performance del modelo y qué hiper parámetros se van a utilizar para el ajuste del modelo acorde a la validación. Finalmente, estas decisiones se vuelcan en la selección del mejor modelo para el problema de la clasificación de correos electrónicos asociados grupos de noticias.\n",
    "\n",
    "### Fuentes útiles\n",
    "* https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "* https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
    "* https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "* https://stackoverflow.com/questions/58046129/can-someone-give-a-good-math-stats-explanation-as-to-what-the-parameter-var-smoo\n",
    "* https://scikit-learn.org/stable/modules/density.html\n",
    "\n",
    "### Integrantes del grupo\n",
    "* Gaytan, Joaquín Oscar\n",
    "* Kammann, Lucas Agustín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Métrica\n",
    "La métrica a utilizar para cuantificar la performance de los modelos, seleccionar los hiperparámetros y validarlos, será la **sensibilidad** o **recall**.\n",
    "\n",
    "## 1.1. Justificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparación de los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Cargando el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database from .csv\n",
    "df = pd.read_csv('../assets/diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de valores inválidos\n",
    "Se filtran los valores inválidos de cada una de las variables, y se los reemplaza utilizando la media obtenida en el conjunto de entrenamiento. Particularmente, se opta por emplear la media de todo el conjunto de entrenamiento, para no introducir sesgo esencialmente dentro del conjunto empleado para la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Glucose values\n",
    "df['Glucose'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Blood Pressure values\n",
    "df['BloodPressure'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Skin Thickness values\n",
    "df['SkinThickness'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Insulin values\n",
    "df['Insulin'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Body Mass Index values\n",
    "df['BMI'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Filtrado de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper import remove_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    remove_outliers(df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Separación de datasets\n",
    "Se separa el dataset original en los datasets de train, valid y test. Además, se debe corregir que los valores inválidos del dataset original fueron reemplazados por el valor NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into the total train and the test datasets, because\n",
    "# the total train contains the train and valid datasets used for\n",
    "# hiper parameter selection\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean of training\n",
    "train_means = train.mean().to_numpy()\n",
    "\n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(train.columns):\n",
    "    train.loc[:,column].replace(np.nan, train_means[index], inplace=True)\n",
    "\n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(test.columns):\n",
    "    test.loc[:,column].replace(np.nan, train_means[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the inputs and outputs of the train dataset\n",
    "x_train = train.to_numpy()[:,:8]\n",
    "y_train = train.to_numpy()[:,8]\n",
    "\n",
    "# Extracting the inputs and outputs of the test dataset\n",
    "x_test = test.to_numpy()[:,:8]\n",
    "y_test = test.to_numpy()[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.859247</td>\n",
       "      <td>122.032787</td>\n",
       "      <td>72.069808</td>\n",
       "      <td>28.893519</td>\n",
       "      <td>135.921311</td>\n",
       "      <td>32.366556</td>\n",
       "      <td>0.431246</td>\n",
       "      <td>32.792763</td>\n",
       "      <td>0.356678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.308473</td>\n",
       "      <td>30.333958</td>\n",
       "      <td>10.708903</td>\n",
       "      <td>8.288153</td>\n",
       "      <td>52.552469</td>\n",
       "      <td>6.605536</td>\n",
       "      <td>0.244934</td>\n",
       "      <td>10.988938</td>\n",
       "      <td>0.479409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>72.069808</td>\n",
       "      <td>28.893519</td>\n",
       "      <td>135.921311</td>\n",
       "      <td>32.366556</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>135.921311</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.585250</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.189000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   614.000000  614.000000     614.000000     614.000000  614.000000   \n",
       "mean      3.859247  122.032787      72.069808      28.893519  135.921311   \n",
       "std       3.308473   30.333958      10.708903       8.288153   52.552469   \n",
       "min       0.000000   44.000000      40.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      65.000000      25.000000  122.000000   \n",
       "50%       3.000000  118.000000      72.069808      28.893519  135.921311   \n",
       "75%       6.000000  141.000000      78.000000      32.000000  135.921311   \n",
       "max      13.000000  199.000000     104.000000      54.000000  360.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  614.000000                614.000000  614.000000  614.000000  \n",
       "mean    32.366556                  0.431246   32.792763    0.356678  \n",
       "std      6.605536                  0.244934   10.988938    0.479409  \n",
       "min     18.200000                  0.084000   21.000000    0.000000  \n",
       "25%     27.500000                  0.238000   24.000000    0.000000  \n",
       "50%     32.366556                  0.381500   29.000000    0.000000  \n",
       "75%     36.800000                  0.585250   40.000000    1.000000  \n",
       "max     50.000000                  1.189000   66.000000    1.000000  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.499086</td>\n",
       "      <td>120.318395</td>\n",
       "      <td>72.282847</td>\n",
       "      <td>28.927850</td>\n",
       "      <td>127.967511</td>\n",
       "      <td>31.575970</td>\n",
       "      <td>0.424461</td>\n",
       "      <td>32.853106</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.106370</td>\n",
       "      <td>30.901014</td>\n",
       "      <td>11.544378</td>\n",
       "      <td>8.147233</td>\n",
       "      <td>46.974638</td>\n",
       "      <td>5.539948</td>\n",
       "      <td>0.245579</td>\n",
       "      <td>11.315674</td>\n",
       "      <td>0.467290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>72.069808</td>\n",
       "      <td>28.893519</td>\n",
       "      <td>135.921311</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>135.921311</td>\n",
       "      <td>35.075000</td>\n",
       "      <td>0.551250</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>49.700000</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   154.000000  154.000000     154.000000     154.000000  154.000000   \n",
       "mean      3.499086  120.318395      72.282847      28.927850  127.967511   \n",
       "std       3.106370   30.901014      11.544378       8.147233   46.974638   \n",
       "min       0.000000   56.000000      44.000000       8.000000   15.000000   \n",
       "25%       1.000000  100.000000      64.000000      25.250000  114.000000   \n",
       "50%       3.000000  116.500000      72.069808      28.893519  135.921311   \n",
       "75%       5.000000  136.750000      80.000000      31.000000  135.921311   \n",
       "max      13.000000  197.000000     104.000000      56.000000  285.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  154.000000                154.000000  154.000000  154.000000  \n",
       "mean    31.575970                  0.424461   32.853106    0.318182  \n",
       "std      5.539948                  0.245579   11.315674    0.467290  \n",
       "min     18.400000                  0.078000   21.000000    0.000000  \n",
       "25%     27.800000                  0.256000   24.000000    0.000000  \n",
       "50%     31.750000                  0.349000   29.000000    0.000000  \n",
       "75%     35.075000                  0.551250   40.000000    1.000000  \n",
       "max     49.700000                  1.191000   66.000000    1.000000  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Selección de modelo e hiper parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Entrenamiento de todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including libraries from sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# Including libraries from scipy\n",
    "from scipy import stats\n",
    "\n",
    "# Including libraries from numpy\n",
    "import numpy as np\n",
    "\n",
    "def gaussian_pdf(value, parameters):\n",
    "    \"\"\" Probability density function of a gaussian distributed continuous random variable.\n",
    "        @param value Value where the pdf is evaluated\n",
    "        @param parameters Values used to parametrize the distribution, such as the mean and the std\n",
    "    \"\"\"\n",
    "    mean = parameters['mean']\n",
    "    std = parameters['std']\n",
    "    return stats.norm.pdf((value - mean) / std) / std\n",
    "\n",
    "def exponential_pdf(value, parameters):\n",
    "    \"\"\" Probability density function of an exponential distributed continuous random variable.\n",
    "        @param value Value where the pdf is evaluated\n",
    "        @param parameters Values used to parametrize the distribution, such as the mean\n",
    "    \"\"\"\n",
    "    _lambda = parameters['lambda']\n",
    "    return stats.expon.pdf(value * _lambda) * _lambda\n",
    "\n",
    "class BinaryNaiveBayes(BaseEstimator):\n",
    "    \"\"\" Implements the Naive Bayes classification criteria to problems with two classes, \n",
    "        allowing parametric distributions based on famous density functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary used to map the type of distribution set in the configuration of the model\n",
    "    # and the function that handles. Basically, a dispatcher of probability density functions\n",
    "    supported_distributions = {\n",
    "        'gaussian': gaussian_pdf,\n",
    "        'exponential': exponential_pdf\n",
    "    }\n",
    "    \n",
    "    def __init__(self, std_correction=False, filter_variables=None, variables_models=None):\n",
    "        \n",
    "        # Parameters of the model, contains the class distribution also known as priori probabilities,\n",
    "        # and the variables parameters used to parametrize the distributions assigned to each variable\n",
    "        # taken into account\n",
    "        self.classes_distribution = None\n",
    "        self.classes_log_distribution = None\n",
    "        self.variables_distributions = None\n",
    "        \n",
    "        # Configuration of the model, also known as the hiper parameters, selection of the\n",
    "        # model settings used to optimize according a specific performance metric\n",
    "        self.std_smoothing = std_smoothing if std_smoothing is not None else 0\n",
    "        self.std_correction = std_correction if std_correction is not None else False\n",
    "        self.filter_variables = filter_variables\n",
    "        self.variables_models = variables_models\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        \"\"\" Fit the model with the training dataset given.\n",
    "            @param x_data Matrix where the rows contain study cases and the columns contain variables or features\n",
    "            @param y_data Array containing the class where the corresponding study case belong\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filtering data if required\n",
    "        if self.filter_variables is not None:\n",
    "            x_data = x_data[:,np.array(self.filter_variables)]\n",
    "        \n",
    "        # Computing the probability distribution of all classes\n",
    "        self.classes_distribution = np.array([len(y_data[y_data == 0]) , len(y_data[y_data == 1])])\n",
    "        self.classes_distribution = self.classes_distribution / self.classes_distribution.sum()\n",
    "        self.classes_log_distribution = np.log(self.classes_distribution)\n",
    "        \n",
    "        # Initializing parameter container\n",
    "        self.variables_parameters = []\n",
    "        \n",
    "        # Fetch the models filtered\n",
    "        models = np.array(self.variables_distributions)[np.array(self.filter_variables)]\n",
    "        \n",
    "        # Calculating mean and standard deviation of variables\n",
    "        for variable_index in range(x_data.shape[1]):\n",
    "            for class_index in range(2):\n",
    "                \n",
    "                # Fit the corresponding distribution assigned to the variable or feature\n",
    "                if self.\n",
    "                self.variables_mean[class_index][variable_index] = np.nanmean(x_data[y_data == class_index, variable_index])\n",
    "                self.variables_std[class_index][variable_index] = np.nanstd(x_data[y_data == class_index, variable_index])\n",
    "                \n",
    "                # Apply Bessel's correction to the standard deviation error \n",
    "                if self.bessel_correction:\n",
    "                    n = (y_data == class_index).sum()\n",
    "                    self.variables_std[class_index][variable_index] = self.variables_std[class_index][variable_index] * np.sqrt((n) / (n-1))\n",
    "            \n",
    "    def predict(self, x_data):\n",
    "        \"\"\" Predict the class of the given input data.\n",
    "            @param x_data Matrix where the rows represent study cases and the columns contain the variables or features to analyze\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filtering data if required\n",
    "        if self.filter_variables is not None:\n",
    "            x_data = x_data[:,np.array(self.filter_variables)]\n",
    "            \n",
    "        # Initialization of predictions\n",
    "        predictions = np.zeros(x_data.shape[0])\n",
    "        \n",
    "        # Fetch the type of distributions\n",
    "        distributions = np.array(self.variables_distributions)[np.array(self.filter_variables)]\n",
    "        \n",
    "        # Prediction for each subject\n",
    "        for subject_index in range(x_data.shape[0]):\n",
    "            \n",
    "            # For each class (positive, negative) compute the log likelihood\n",
    "            log_likelihood = np.array(\n",
    "                [\n",
    "                    np.log(\n",
    "                        self.supported_distributions[distributions[variable_index]](\n",
    "                            np.array([x_data[subject_index, variable_index] for i in range(2)]), \n",
    "                            self.variables_mean[:, variable_index], \n",
    "                            self.variables_std[:, variable_index] + self.smoothing\n",
    "                        )\n",
    "                    )\n",
    "                    for variable_index in range(x_data.shape[1])\n",
    "                ]\n",
    "            ).sum(axis=0)\n",
    "\n",
    "            # Compute the log posteriori unnormalized and predict\n",
    "            log_posteriori_unnormalized = log_likelihood + self.log_priori_distribution\n",
    "            predictions[subject_index] = 1 if log_posteriori_unnormalized[1] > log_posteriori_unnormalized[0] else 0\n",
    "        \n",
    "        # Return the predictions made by the model\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Búsqueda del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Hiper parameters\n",
    "parameters = {\n",
    "    'smoothing': [0],\n",
    "    'bessel_correction': [False, True],\n",
    "    'filter_variables': list(itertools.product([True, False], repeat=8)),\n",
    "    'variables_distributions': list(itertools.product(['gaussian', 'exponential'], repeat=8))\n",
    "}\n",
    "\n",
    "# Estimator or model\n",
    "estimator = BinaryNaiveBayes()\n",
    "\n",
    "# GridSearch Cross-Validation\n",
    "grid = GridSearchCV(estimator, parameters, cv=2, scoring='recall', n_jobs=-1)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13982733 0.12352915 0.13322312 0.13769068 0.14566054 0.15064078\n",
      " 0.13788783 0.15489862 0.1296138  0.11888205 0.14031653 0.1454927\n",
      " 0.14386318 0.13066683 0.13461839 0.1411286  0.15224343 0.14982042\n",
      " 0.15164502 0.14020658 0.13639343 0.11942394 0.13189924 0.14580557\n",
      " 0.14423311 0.15127575 0.15538071 0.13530837 0.13018426 0.12771773\n",
      " 0.12780679 0.13262705 0.14574343 0.11152302 0.13344825 0.12214079\n",
      " 0.14097944 0.13500021 0.14773403 0.15228223 0.12997736 0.12088271\n",
      " 0.11787785 0.11646893 0.1500729  0.14997126 0.14363061 0.13848072\n",
      " 0.15072644 0.13749571 0.15213447 0.12551807 0.14548354 0.13921248\n",
      " 0.13621628 0.12970173 0.14506799 0.11822153 0.14248933 0.12195976\n",
      " 0.13579715 0.1201416  0.12097858 0.12970173 0.14223443 0.13179208\n",
      " 0.13691623 0.11301223 0.14429445 0.13016406 0.13379332 0.1224398\n",
      " 0.13027479 0.14370411 0.14901826 0.12198762 0.15200741 0.13913634\n",
      " 0.13225284 0.13768913 0.14920295 0.14566614 0.15117307 0.13972853\n",
      " 0.15313099 0.14257774 0.14055807 0.1429472  0.1515879  0.14992813\n",
      " 0.17007108 0.13212848 0.16258965 0.16338936 0.15133879 0.15558344\n",
      " 0.12520596 0.13430153 0.11620583 0.11436219 0.10066934 0.14209087\n",
      " 0.12023104 0.11700367 0.1296865  0.14007987 0.11379709 0.1109523\n",
      " 0.11785507 0.14917142 0.11414121 0.11499907 0.16344096 0.11833628\n",
      " 0.13632693 0.11262241 0.11939662 0.14754296 0.12822631 0.13096831\n",
      " 0.1504394  0.15065343 0.14363118 0.12125962 0.13548233 0.15302534\n",
      " 0.12979799 0.13196698 0.11420016 0.10909782 0.10390825 0.11572222\n",
      " 0.13041369 0.12516501 0.12346381 0.12325821 0.11228969 0.11962234\n",
      " 0.10536424 0.12023553 0.1336225  0.10976315 0.12961443 0.11454293\n",
      " 0.14439019 0.1116442  0.14864457 0.10821558 0.12172074 0.10946145\n",
      " 0.12001732 0.10755903 0.12879134 0.1223727  0.12775434 0.1146917\n",
      " 0.11955211 0.11962967 0.09976211 0.10610541 0.12948151 0.10069574\n",
      " 0.11606691 0.09544268 0.12693321 0.10311386 0.12236105 0.10308111\n",
      " 0.11351224 0.09665682 0.10079056 0.09276865 0.13409633 0.10859722\n",
      " 0.11416287 0.08961094 0.14380846 0.11337209 0.12685513 0.11045289\n",
      " 0.1307686  0.10254748 0.12027422 0.11113328 0.13183243 0.11353503\n",
      " 0.10809926 0.11023644 0.11843611 0.10740737 0.10931544 0.11128362\n",
      " 0.14814796 0.11108974 0.1106529  0.09685862 0.14409368 0.13316719\n",
      " 0.1212442  0.12139854 0.16119077 0.14001968 0.12468388 0.1036411\n",
      " 0.15264731 0.15628758 0.12509615 0.12414724 0.1550463  0.11528482\n",
      " 0.14780094 0.1122565  0.13774905 0.12916895 0.12102193 0.10434621\n",
      " 0.16681701 0.12832275 0.14658205 0.10075045 0.15709109 0.13692616\n",
      " 0.13554736 0.13009016 0.12102299 0.11890615 0.10938398 0.08640743\n",
      " 0.14890677 0.13819658 0.08844153 0.11010458 0.11610499 0.11462063\n",
      " 0.11392882 0.08805591 0.14798277 0.12924379 0.09488674 0.09254557\n",
      " 0.14310504 0.12200592 0.13297316 0.09028859 0.1321455  0.11745441\n",
      " 0.12182561 0.12472768 0.15491865 0.13504033 0.13047269 0.10610476\n",
      " 0.14378233 0.12539368 0.13143628 0.09633522 0.13982733 0.12352915\n",
      " 0.13322312 0.13769068 0.14566054 0.15064078 0.13788783 0.15489862\n",
      " 0.1296138  0.11888205 0.14031653 0.1454927  0.14386318 0.13066683\n",
      " 0.13461839 0.1411286  0.15224343 0.14982042 0.15164502 0.14020658\n",
      " 0.13639343 0.1291296  0.13189924 0.15178837 0.13981083 0.15127575\n",
      " 0.15538071 0.13530837 0.13018426 0.12771773 0.12780679 0.13262705\n",
      " 0.14574343 0.11152302 0.13344825 0.12214079 0.14097944 0.13500021\n",
      " 0.14773403 0.15228223 0.12997736 0.12088271 0.11787785 0.11646893\n",
      " 0.1500729  0.14997126 0.14363061 0.13848072 0.15072644 0.13749571\n",
      " 0.15213447 0.12551807 0.14548354 0.13647686 0.13621628 0.12970173\n",
      " 0.14506799 0.11822153 0.14248933 0.11567719 0.13579715 0.1201416\n",
      " 0.12097858 0.12970173 0.13617104 0.13179208 0.13691623 0.11301223\n",
      " 0.14429445 0.13016406 0.13379332 0.12380664 0.13027479 0.14370411\n",
      " 0.14901826 0.12198762 0.15200741 0.14269326 0.14003574 0.13768913\n",
      " 0.14920295 0.15099332 0.15117307 0.13972853 0.15313099 0.14257774\n",
      " 0.14055807 0.1429472  0.15796384 0.14992813 0.17007108 0.13239336\n",
      " 0.16258965 0.16338936 0.15133879 0.15558344 0.12520596 0.13430153\n",
      " 0.11620583 0.11436219 0.11783246 0.1446899  0.12023104 0.11700367\n",
      " 0.1296865  0.14007987 0.11379709 0.1109523  0.11785507 0.14917142\n",
      " 0.11414121 0.11499907 0.16344096 0.11833628 0.13632693 0.11262241\n",
      " 0.11939662 0.14686978 0.12822631 0.13096831 0.14896634 0.15065343\n",
      " 0.14220702 0.12026559 0.13548233 0.15302534 0.12979799 0.13196698\n",
      " 0.11830023 0.112602   0.10390825 0.11572222 0.13041369 0.12516501\n",
      " 0.12346381 0.12325821 0.11228969 0.11962234 0.10536424 0.12023553\n",
      " 0.14077847 0.10976315 0.12961443 0.11454293 0.14439019 0.1116442\n",
      " 0.14864457 0.10821558 0.12172074 0.1065374  0.12001732 0.10755903\n",
      " 0.12879134 0.11609872 0.12775434 0.1146917  0.11955211 0.11962967\n",
      " 0.09922163 0.10610541 0.12948151 0.10069574 0.11606691 0.09544268\n",
      " 0.12693321 0.10311386 0.12236105 0.10308111 0.11351224 0.09665682\n",
      " 0.10079056 0.09276865 0.13409633 0.10859722 0.11416287 0.08961094\n",
      " 0.14380846 0.11337209 0.12685513 0.10336567 0.1307686  0.10254748\n",
      " 0.12027422 0.11113328 0.13183243 0.11353503 0.11223049 0.11023644\n",
      " 0.11843611 0.10740737 0.10931544 0.11128362 0.14814796 0.11596967\n",
      " 0.1106529  0.09685862 0.14409368 0.13316719 0.12805461 0.12139854\n",
      " 0.16630124 0.14001968 0.12468388 0.1036411  0.15264731 0.15628758\n",
      " 0.12402888 0.12414724 0.1550463  0.11528482 0.14780094 0.1122565\n",
      " 0.13774905 0.12916895 0.12102193 0.11035801 0.16681701 0.12832275\n",
      " 0.14658205 0.10075045 0.15709109 0.13692616 0.13554736 0.13009016\n",
      " 0.12102299 0.11890615 0.10938398 0.08640743 0.14035557 0.13819658\n",
      " 0.09377753 0.11010458 0.12385785 0.11462063 0.11392882 0.090486\n",
      " 0.14798277 0.12924379 0.09488674 0.10574772 0.14310504 0.12200592\n",
      " 0.13297316 0.09028859 0.1321455  0.11745441 0.12182561 0.12472768\n",
      " 0.14700758 0.13504033 0.13047269 0.10433983 0.14378233 0.12539368\n",
      " 0.13143628 0.09633522]\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bessel_correction': False,\n",
      " 'filter_variables': (True, True, True, True, True, True, True, True),\n",
      " 'smoothing': 0,\n",
      " 'variables_distributions': ('gaussian',\n",
      "                             'gaussian',\n",
      "                             'gaussian',\n",
      "                             'gaussian',\n",
      "                             'exponential',\n",
      "                             'gaussian',\n",
      "                             'gaussian',\n",
      "                             'gaussian')}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6102681335692172\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Entrenamiento completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "classifier = BinaryNaiveBayes(\n",
    "    smoothing=grid.best_params_['smoothing'], \n",
    "    bessel_correction=grid.best_params_['bessel_correction'], \n",
    "    filter_variables=grid.best_params_['filter_variables'],\n",
    "    variables_distributions=('exponential',\n",
    "                             'gaussian',\n",
    "                             'exponential',\n",
    "                             'gaussian',\n",
    "                             'gaussian',\n",
    "                             'gaussian',\n",
    "                             'exponential',\n",
    "                             'gaussian')\n",
    ")\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validación y performance del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Contrastando con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create and train the model\n",
    "c = GaussianNB()\n",
    "c.fit(x_train, y_train)\n",
    "\n",
    "# Predict and compute score\n",
    "p = c.predict(x_test)\n",
    "score = recall_score(y_test, p)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
