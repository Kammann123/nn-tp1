{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVaG71Po2qOD"
   },
   "source": [
    "# Redes Neuronales\n",
    "## Trabajo Práctico N° 1 - Ejercicio 1\n",
    "* Kammann, Lucas Agustín\n",
    "* Gaytan, Joaquín Oscar\n",
    "\n",
    "### Consultas y/o dudas\n",
    "* Métricas del modelo (Matriz de confusión, exactitud, precisión, etc.)\n",
    "* Procesamiento de los datos? (Filtrado)\n",
    "* CountVectorizer, es necesario que lo hagamos a mano o podemos utilizar la librería de sci-kit-learn?\n",
    "* Filtrado de numeros\n",
    "* Filtrado de palabras\n",
    "\n",
    "### Step by step\n",
    "* Obtención del dataset (separando entre \"train\" y \"test\")\n",
    "* Preprocesamiento de los datos\n",
    "* Distribuciones condicionales (Verosimilitudes/Likelihood)\n",
    "* Smoothing\n",
    "* Probabilidad a Priori\n",
    "* Clasificación (Naive Bayes Multinomial)\n",
    "* Clasificación usando log posteriori\n",
    "* Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del problema\n",
    "Se desea armar un clasificador de correos electrónicos o noticias en función del tópico sobre el cual trata dicho correo electrónico o noticia, para ello, se modela el problema considerando una variable aleatoria discreta $X$ con distribución categórica de $k_x = 20$ categorías, siendo estas los tópicos posibles que pueden tratar los documentos clasificados.\n",
    "\n",
    "$$X \\sim Categorica(p_1, p_2, ..., p_{k_x})$$\n",
    "\n",
    "Las características a analizar de los documentos para la clasificación, son las palabras. Se asume que el orden de las palabras no importa, que son independientes entre sí y que se encuentran identicamente distribuídas. De esta forma, se define una segunda variable aleatoria discreta $Y$ con distribución categórica de $k_y$ categorías, siendo estas las posibles palabras de nuestro vocabulario.\n",
    "\n",
    "$$Y \\sim Categorica(p_1, p_2, ..., p_{k_y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de la base de datos\n",
    "Usamos la librería **sklearn** para descargar la base de datos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18842,
     "status": "ok",
     "timestamp": 1616464689182,
     "user": {
      "displayName": "JOAQUÍN OSCAR GAYTAN",
      "photoUrl": "",
      "userId": "15176508666834216481"
     },
     "user_tz": 180
    },
    "id": "NCv8VNLQ2k7R",
    "outputId": "270d983e-17a6-4a3a-c82f-f6e6a0ce6faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Train: 11314 elements\n",
      "Dataset Test: 7532 elements\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "# Loading the datasets\n",
    "train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# Categories\n",
    "categories = train.target_names\n",
    "\n",
    "# Train dataset, casting to numpy array\n",
    "train_data = np.array(train.data)\n",
    "train_target = np.array(train.target)\n",
    "train_size = len(train_data)\n",
    "\n",
    "# Test dataset, casting to numpy array\n",
    "test_data = np.array(test.data)\n",
    "test_target = np.array(test.target)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# Logging useful information\n",
    "print(f'Dataset Train: {train_size} elements')\n",
    "print(f'Dataset Test: {test_size} elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando la base de datos\n",
    "\n",
    "## Observando un correo electrónico de forma aleatoria\n",
    "Buscamos de forma aleatoria un elemento dentro de la base de datos de entrenamiento, con el objetivo de visualizar cómo suelen ser los correos electrónicos de noticias que se poseen, para tener una mejor comprensión de qué podemos llegar a encontrarnos dentro del vocabulario o el documento a analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: kja@watson.ibm.com ( Kenneth J. Arbeitman)\n",
      "Subject: Missing subject header\n",
      "Reply-To: kja@bones.fishkill.ibm.com ( Kenneth J. Arbeitman)\n",
      "Disclaimer: This posting represents the poster's views, not necessarily those of IBM\n",
      "Nntp-Posting-Host: bones.fishkill.ibm.com\n",
      "Organization: IBM East Fishkill                                                        Subject: Re: Torre: The worst manager?\n",
      "Lines: 39\n",
      "\n",
      "\n",
      "In article <93095@hydra.gatech.EDU>, gt7469a@prism.gatech.EDU (Brian R.\n",
      "Landmann) writes:\n",
      "|> Joe Torre has to be the worst manager in baseball.\n",
      "|> \n",
      "|> For anyone who didn't see Sunday's game,\n",
      "|> \n",
      "|> With a right hander pitching he decides to bench Lankform, a left handed\n",
      "|> hitter and play jordan and gilkey, both right handers.\n",
      "  \n",
      "    That's because Lankford had a minor injury from a couple of games\n",
      "before that\n",
      "    and was day-to-day... only available as a pinchrunner. \n",
      "\n",
      "|> \n",
      "|> Later, in the ninth inning with the bases loaded and two outs he puts\n",
      "|> lankford, a 300 hitter with power in as a pinch runner and uses Luis\n",
      "|> Alicea, a 250 hitter with no power as a pinch hitter.  What the Hell\n",
      "|> is he thinking.\n",
      "\n",
      "     See above.\n",
      "|> \n",
      "|> Earlier in the game in an interview about acquiring Mark Whiten he commented\n",
      "|> how fortunate the Cardinals were to get Whiten and that Whiten would be a\n",
      "|> regular even though this meant that Gilkey would be hurt, But torre said\n",
      "|> he liked Gilkey coming off the bench.  Gilkey hit over 300 last year,\n",
      "|> what does he have to do to start, The guy would be starting on most every\n",
      "|> team in the league.\n",
      "|> \n",
      "    At the beginning of the interview Torre also said Lankford is the\n",
      "one outfield\n",
      "    guy who's \"in there no matter what\".\n",
      "    My guess is Jordan will eventually end up being odd man out due to low\n",
      "    on base percentage.  Whiten was a great acquisition... decent offense\n",
      "    and great defense in rightfield.  But don't worry, Gilkey will be\n",
      "starting        \n",
      "    as soon as Jordan or Whiten displays an extended period of low offensive\n",
      "    output.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_data = np.random.choice(train_data)\n",
    "print(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorías\n",
    "Dentro de la base de datos, los correos electrónicos que podemos encontrar pueden tratar de diferentes tópicos, y estos tópicos son las categorías de la variable aleatoria definida $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1616464712787,
     "user": {
      "displayName": "JOAQUÍN OSCAR GAYTAN",
      "photoUrl": "",
      "userId": "15176508666834216481"
     },
     "user_tz": 180
    },
    "id": "9Xh-PLNI7WsW",
    "outputId": "1665e32b-4e8b-491f-f4a2-d4115f937cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Show the news categories\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "      \"alt\": {\n",
      "            \"atheism\": {}\n",
      "      },\n",
      "      \"comp\": {\n",
      "            \"graphics\": {},\n",
      "            \"os\": {\n",
      "                  \"ms-windows\": {\n",
      "                        \"misc\": {}\n",
      "                  }\n",
      "            },\n",
      "            \"sys\": {\n",
      "                  \"ibm\": {\n",
      "                        \"pc\": {\n",
      "                              \"hardware\": {}\n",
      "                        }\n",
      "                  },\n",
      "                  \"mac\": {\n",
      "                        \"hardware\": {}\n",
      "                  }\n",
      "            },\n",
      "            \"windows\": {\n",
      "                  \"x\": {}\n",
      "            }\n",
      "      },\n",
      "      \"misc\": {\n",
      "            \"forsale\": {}\n",
      "      },\n",
      "      \"rec\": {\n",
      "            \"autos\": {},\n",
      "            \"motorcycles\": {},\n",
      "            \"sport\": {\n",
      "                  \"baseball\": {},\n",
      "                  \"hockey\": {}\n",
      "            }\n",
      "      },\n",
      "      \"sci\": {\n",
      "            \"crypt\": {},\n",
      "            \"electronics\": {},\n",
      "            \"med\": {},\n",
      "            \"space\": {}\n",
      "      },\n",
      "      \"soc\": {\n",
      "            \"religion\": {\n",
      "                  \"christian\": {}\n",
      "            }\n",
      "      },\n",
      "      \"talk\": {\n",
      "            \"politics\": {\n",
      "                  \"guns\": {},\n",
      "                  \"mideast\": {},\n",
      "                  \"misc\": {}\n",
      "            },\n",
      "            \"religion\": {\n",
      "                  \"misc\": {}\n",
      "            }\n",
      "      }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Processing the categories tree\n",
    "categories_tree = {}\n",
    "for category in categories:\n",
    "    # For each new category, the dot separated fields are converted into a list\n",
    "    category_levels = category.split('.')\n",
    "    \n",
    "    # Iteration over each field that describes a category, to create the corresponding\n",
    "    # tree path towards that node, each field should exist as a node in its corresponding level\n",
    "    categories_tree_node = categories_tree\n",
    "    for category_level in category_levels:\n",
    "            # If current category level has not been created already\n",
    "            if category_level not in categories_tree_node.keys():\n",
    "                categories_tree_node[category_level] = {}\n",
    "                \n",
    "            # Enter the category level\n",
    "            categories_tree_node = categories_tree_node[category_level]\n",
    "\n",
    "# Showing the result in a graphical view\n",
    "print(json.dumps(categories_tree, indent=6, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO! Agregar labels para cada posible categoria, más lindo el histograma y explicar la PROBABILIDAD A PRIORI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograma de tópicos\n",
    "Se calcula y grafica el histograma de los tópicos de las noticias o correos electrónicos utilizando la librería **matplotlib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 4780,
     "status": "ok",
     "timestamp": 1616376899482,
     "user": {
      "displayName": "LUCAS KAMMANN",
      "photoUrl": "",
      "userId": "12661655261825067035"
     },
     "user_tz": 180
    },
    "id": "R7Jl_PbkC7CY",
    "outputId": "9fbc462e-28ed-4cc0-b7a7-9254af2e7597"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04242531 0.05161747 0.05223617 0.05214778 0.05108715 0.05241294\n",
      " 0.05170585 0.05250133 0.05285487 0.05276648 0.05303164 0.05258971\n",
      " 0.05223617 0.05250133 0.05241294 0.05294326 0.04825879 0.04984974\n",
      " 0.04109952 0.03332155]\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Histogram for the categories in the training set\n",
    "priori, _, _ = plt.hist(train_target, bins=len(categories), range=(0,len(categories)), rwidth=0.5, density=True)\n",
    "plt.show()\n",
    "print(priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the priori probability distribution: (20,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the priori probability distribution: {priori.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de probabilidades a priori\n",
    "Se computan las probabilidades a priori para las categorías, es decir, los tópicos. Se emplea una herramienta distinta a **matplotlib** para comparar el tiempo utilizada en el procesamiento. Se está estimando la siguiente función masa de probabilidad,\n",
    "$$P(X=x) ; x = 0, 1, ..., 19$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For each category, filter the amount of occurences in the training dataset\n",
    "# the compute the priori probability\n",
    "priori_distribution = np.zeros(len(categories))\n",
    "for index, category in enumerate(categories):\n",
    "    frequency = (train_target == index).sum()\n",
    "    priori_distribution[index] = frequency\n",
    "priori_distribution /= priori_distribution.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VTY7lCEeMQWC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Importing and testing the CountVectorizer class of sklearn\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words='english')\n",
    "feature_matrix = vectorizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 129796)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de distribución de probabilidad condicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zbu8XISsgck7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Separate the matrix of documents (mails) and occurrences of words for each category\n",
    "# and compute the normalized distribution to get the likelihood for each category\n",
    "alpha = 1\n",
    "categories_distribution = np.zeros((len(categories), len(vectorizer.vocabulary_.keys())), dtype=np.longdouble)\n",
    "for index, category in enumerate(categories):\n",
    "  category_matrix = feature_matrix[train_target == index][:]\n",
    "  distribution = category_matrix.sum(axis=0) + alpha\n",
    "  categories_distribution[index,:] = distribution / distribution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 129796)\n",
      "[[1.87142383e-05 1.63749585e-04 4.67855957e-06 ... 4.67855957e-06\n",
      "  4.67855957e-06 4.67855957e-06]\n",
      " [1.63359035e-04 8.40132181e-05 4.66740100e-06 ... 4.66740100e-06\n",
      "  4.66740100e-06 4.66740100e-06]\n",
      " [9.18720277e-05 2.97233031e-05 2.70211846e-06 ... 2.70211846e-06\n",
      "  2.70211846e-06 2.70211846e-06]\n",
      " ...\n",
      " [1.23957752e-04 7.54683962e-04 7.29163249e-06 ... 3.64581624e-06\n",
      "  3.64581624e-06 3.64581624e-06]\n",
      " [1.21906620e-04 2.98461034e-04 4.20367654e-06 ... 4.20367654e-06\n",
      "  4.20367654e-06 4.20367654e-06]\n",
      " [2.52340458e-05 9.08425648e-05 5.04680915e-06 ... 5.04680915e-06\n",
      "  5.04680915e-06 5.04680915e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(categories_distribution.shape)\n",
    "print(categories_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando la prediccion con las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Data, target and vectorizer\n",
    "input_size = 100\n",
    "input_data = test_data[:input_size]\n",
    "input_target = test_target[:input_size]\n",
    "input_matrix = vectorizer.transform(input_data)\n",
    "\n",
    "# Computing predictions for each input\n",
    "predictions = np.zeros(input_matrix.shape[0], dtype=int)\n",
    "for input_index in range(input_matrix.shape[0]):\n",
    "    # Computing the posteriori probability\n",
    "    # posteriori_unnormalized = ((categories_distribution * 10e3) ** input_matrix.toarray()[input_index]).prod(axis=1) * priori\n",
    "    posteriori_unnormalized = ((categories_distribution) ** input_matrix.toarray()[input_index]).prod(axis=1) * priori\n",
    "    posteriori_normalized = posteriori_unnormalized / posteriori_unnormalized.sum()\n",
    "\n",
    "    # Choosing the maximum posteriori probability as the prediction\n",
    "    predictions[input_index] = posteriori_unnormalized.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Computing the accuracy of the model\n",
    "accuracy = (predictions == input_target).sum() / input_size\n",
    "print(f'Accuracy obtained: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando la predicción usando log probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Log probabilities\n",
    "log_priori = np.log(priori)\n",
    "log_prob = np.log(categories_distribution)\n",
    "\n",
    "# Data, target and vectorizer\n",
    "input_size = 10#test_size\n",
    "input_data = test_data[:input_size]\n",
    "input_target = test_target[:input_size]\n",
    "input_matrix = vectorizer.transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Computing the log posteriori probability\n",
    "log_posteriori = np.dot(log_prob, input_matrix.todense().transpose()) + (log_priori.reshape(-1, 1) * np.ones(input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Choosing the maximum log posteriori probability as the prediction\n",
    "predictions = np.zeros(input_matrix.shape[0], dtype=int)\n",
    "for input_index in range(input_size):\n",
    "    predictions[input_index] = log_posteriori[:,input_index].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Computing the accuracy of the model\n",
    "accuracy = (predictions == input_target).sum() / input_size\n",
    "print(f'Accuracy obtained: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP1-EJ1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
